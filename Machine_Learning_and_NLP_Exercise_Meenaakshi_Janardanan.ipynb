{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and NLP Exercises #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the same review data set from Kaggle from Week 2 for this exercise. The product we'll focus on this time is a cappuccino cup. The goal of this week is to not only preprocess the data, but to classify reviews as positive or negative based on the review text.\n",
    "\n",
    "The following code will help you load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2XP9IN4JOMROD</td>\n",
       "      <td>1</td>\n",
       "      <td>I wanted to love this. I was even prepared for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2TS09JCXNV1VD</td>\n",
       "      <td>5</td>\n",
       "      <td>Grove Square Cappuccino Cups were excellent. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AJ3L5J7GN09SV</td>\n",
       "      <td>2</td>\n",
       "      <td>I bought the Grove Square hazelnut cappuccino ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3CZD34ZTUJME7</td>\n",
       "      <td>1</td>\n",
       "      <td>I love my Keurig, and I love most of the Keuri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWKN396SHAQGP</td>\n",
       "      <td>1</td>\n",
       "      <td>It's a powdered drink. No filter in k-cup.&lt;br ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A35NA371SV1PAH</td>\n",
       "      <td>3</td>\n",
       "      <td>Not enough coffee flavor and definitely to swe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A1LR5HPNQLH4RI</td>\n",
       "      <td>1</td>\n",
       "      <td>don't bother! bet you couldn't tell the differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A2RCZ8YKLE8B3O</td>\n",
       "      <td>1</td>\n",
       "      <td>Never tasted this coffee before, I felt much t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A31D6GWYLIKF4X</td>\n",
       "      <td>2</td>\n",
       "      <td>While the overall idea behind the product is l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A1KZPDB5MOWNVU</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought a keurig and bought these to try. Wel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  stars                                            reviews\n",
       "0  A2XP9IN4JOMROD      1  I wanted to love this. I was even prepared for...\n",
       "1  A2TS09JCXNV1VD      5  Grove Square Cappuccino Cups were excellent. T...\n",
       "2   AJ3L5J7GN09SV      2  I bought the Grove Square hazelnut cappuccino ...\n",
       "3  A3CZD34ZTUJME7      1  I love my Keurig, and I love most of the Keuri...\n",
       "4   AWKN396SHAQGP      1  It's a powdered drink. No filter in k-cup.<br ...\n",
       "5  A35NA371SV1PAH      3  Not enough coffee flavor and definitely to swe...\n",
       "6  A1LR5HPNQLH4RI      1  don't bother! bet you couldn't tell the differ...\n",
       "7  A2RCZ8YKLE8B3O      1  Never tasted this coffee before, I felt much t...\n",
       "8  A31D6GWYLIKF4X      2  While the overall idea behind the product is l...\n",
       "9  A1KZPDB5MOWNVU      5  I bought a keurig and bought these to try. Wel..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('coffee.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Determine how many reviews there are in total.\n",
    "* Determine the percent of 1, 2, 3, 4 and 5 star reviews.\n",
    "* Create a new data set for modeling with the following columns:\n",
    "     - Column 1: 'positive' if review = 4 or 5, and 'negative' if review = 1 or 2\n",
    "     - Column 2: review text\n",
    "* Take a look at the number of positive and negative reviews in the newly created data set.\n",
    "\n",
    "Checkpoint: the resulting data set should have 514 reviews.\n",
    "\n",
    "Use the preprocessing code below to clean the reviews data before moving on to modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews - 542\n"
     ]
    }
   ],
   "source": [
    "print(\"Total reviews -\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>counts</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>17.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>8.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>11.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>308</td>\n",
       "      <td>56.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars  counts  percent\n",
       "0      1      96    17.71\n",
       "1      2      45     8.30\n",
       "2      3      28     5.17\n",
       "3      4      65    11.99\n",
       "4      5     308    56.83"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution = data.groupby(\"stars\",as_index=False).size().reset_index()\n",
    "distribution.columns = ['stars','counts']\n",
    "distribution['percent'] = np.round(distribution.counts/np.sum(distribution.counts)*100,2)\n",
    "distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews in new dataset -  514\n"
     ]
    }
   ],
   "source": [
    "data1 = data[data.stars!=3].reset_index(drop=True)\n",
    "dataset = pd.DataFrame()\n",
    "dataset[\"sentiment\"] = np.where(data1.stars>=4,\"positive\",\"negative\")\n",
    "dataset[\"reviews\"] = data1.reviews\n",
    "print(\"Number of reviews in new dataset - \",len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>i wanted to love this  i was even prepared for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>grove square cappuccino cups were excellent  t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>i bought the grove square hazelnut cappuccino ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>i love my keurig  and i love most of the keuri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>it s a powdered drink  no filter in k cup  br ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>don t bother  bet you couldn t tell the differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>negative</td>\n",
       "      <td>never tasted this coffee before  i felt much t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative</td>\n",
       "      <td>while the overall idea behind the product is l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>positive</td>\n",
       "      <td>i bought a keurig and bought these to try  wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "      <td>my husband and i love this french vanilla capp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                            reviews\n",
       "0  negative  i wanted to love this  i was even prepared for...\n",
       "1  positive  grove square cappuccino cups were excellent  t...\n",
       "2  negative  i bought the grove square hazelnut cappuccino ...\n",
       "3  negative  i love my keurig  and i love most of the keuri...\n",
       "4  negative  it s a powdered drink  no filter in k cup  br ...\n",
       "5  negative  don t bother  bet you couldn t tell the differ...\n",
       "6  negative  never tasted this coffee before  i felt much t...\n",
       "7  negative  while the overall idea behind the product is l...\n",
       "8  positive  i bought a keurig and bought these to try  wel...\n",
       "9  positive  my husband and i love this french vanilla capp..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
    "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "dataset['reviews'] = dataset.reviews.map(alphanumeric).map(punc_lower)\n",
    "dataset.head(10)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Prepare the data for modeling:\n",
    "* Split the data into training and test sets. You should have four sets of data - X_train, X_test, y_train, y_test\n",
    "\n",
    "Create numerical features with Count Vectorizer. Create two document-term matrices:\n",
    "* Matrix 1: Terms should be unigrams (single words), and values should be word counts (Hint: this is the Count Vectorizer default)\n",
    "* Matrix 2: Terms should be unigrams and bigrams, and values should be binary values\n",
    "\n",
    "Recommendation: Utilize Count Vectorizer's stop words function to remove stop words from the reviews text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>0g</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>10oz</th>\n",
       "      <th>11</th>\n",
       "      <th>11s</th>\n",
       "      <th>12</th>\n",
       "      <th>170mg</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yessiree</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yucky</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2084 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  0g  10  100  10oz  11  11s  12  170mg  18  ...  yes  yessiree  \\\n",
       "0   0   0   0    0     0   0    0   0      0   0  ...    0         0   \n",
       "1   0   0   0    0     0   0    0   0      0   0  ...    0         0   \n",
       "2   0   0   0    0     0   0    0   0      0   0  ...    0         0   \n",
       "3   0   0   0    0     0   0    0   0      0   0  ...    0         0   \n",
       "4   0   0   0    0     0   0    0   0      0   0  ...    0         0   \n",
       "\n",
       "   yesterday  york  yuck  yucky  yum  yummy  yup  sentiment  \n",
       "0          0     0     0      0    0      0    0   negative  \n",
       "1          0     0     0      0    0      0    0   positive  \n",
       "2          0     0     0      0    0      0    0   negative  \n",
       "3          0     0     0      0    0      0    0   negative  \n",
       "4          0     0     0      0    0      0    0   negative  \n",
       "\n",
       "[5 rows x 2084 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "cv.fit(dataset.reviews)\n",
    "dtm = cv.transform(dataset.reviews)\n",
    "matrix1 = pd.DataFrame(dtm.toarray(), columns=cv.get_feature_names())\n",
    "matrix1[\"sentiment\"] = dataset.sentiment\n",
    "matrix1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(matrix1.drop(\"sentiment\",axis=1),matrix1[[\"sentiment\"]],test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00 cups</th>\n",
       "      <th>00 thought</th>\n",
       "      <th>0g</th>\n",
       "      <th>0g protein</th>\n",
       "      <th>10</th>\n",
       "      <th>10 00</th>\n",
       "      <th>10 2012</th>\n",
       "      <th>10 47</th>\n",
       "      <th>10 bought</th>\n",
       "      <th>...</th>\n",
       "      <th>yummy price</th>\n",
       "      <th>yummy real</th>\n",
       "      <th>yummy run</th>\n",
       "      <th>yummy strong</th>\n",
       "      <th>yummy suitable</th>\n",
       "      <th>yummy treat</th>\n",
       "      <th>yummy won</th>\n",
       "      <th>yup</th>\n",
       "      <th>yup exactly</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10720 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  00 cups  00 thought  0g  0g protein  10  10 00  10 2012  10 47  \\\n",
       "0   0        0           0   0           0   0      0        0      0   \n",
       "1   0        0           0   0           0   0      0        0      0   \n",
       "2   0        0           0   0           0   0      0        0      0   \n",
       "3   0        0           0   0           0   0      0        0      0   \n",
       "4   0        0           0   0           0   0      0        0      0   \n",
       "\n",
       "   10 bought  ...  yummy price  yummy real  yummy run  yummy strong  \\\n",
       "0          0  ...            0           0          0             0   \n",
       "1          0  ...            0           0          0             0   \n",
       "2          0  ...            0           0          0             0   \n",
       "3          0  ...            0           0          0             0   \n",
       "4          0  ...            0           0          0             0   \n",
       "\n",
       "   yummy suitable  yummy treat  yummy won  yup  yup exactly  sentiment  \n",
       "0               0            0          0    0            0   negative  \n",
       "1               0            0          0    0            0   positive  \n",
       "2               0            0          0    0            0   negative  \n",
       "3               0            0          0    0            0   negative  \n",
       "4               0            0          0    0            0   negative  \n",
       "\n",
       "[5 rows x 10720 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english',ngram_range=(1,2),binary=1)\n",
    "cv.fit(dataset.reviews)\n",
    "dtm = cv.transform(dataset.reviews)\n",
    "matrix2 = pd.DataFrame(dtm.toarray(), columns=cv.get_feature_names())\n",
    "matrix2[\"sentiment\"] = dataset.sentiment\n",
    "matrix2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(matrix2.drop(\"sentiment\",axis=1),matrix2[[\"sentiment\"]],test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Logistic Regression to classify reviews as positive or negative. Do this for both matrices.\n",
    "* Fit a Logistic Regression model on the training data\n",
    "* Apply the model on the test data and calculate the following error metrics: accuracy, precision, recall, F1 score\n",
    "* Optional: Visualize the confusion matrix for both models\n",
    "* Compare the error metrics of the two matrices\n",
    "\n",
    "Recommendation: Create a function to calculate the error metrics, since you'll be doing this multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errors_metrics(test,preds):\n",
    "    cm = confusion_matrix(test,preds)\n",
    "    print(\"Accuracy -\",(cm[0,0]+cm[1,1])/np.sum(cm))\n",
    "    vals = precision_recall_fscore_support(test, preds,average='weighted')\n",
    "    print(\"Precision -\",vals[0])\n",
    "    print(\"Recall -\",vals[1])\n",
    "    print(\"f1_score -\",vals[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "matrix1 - Train Data -\n",
      "Accuracy - 0.9974025974025974\n",
      "Precision - 0.9974118408282109\n",
      "Recall - 0.9974025974025974\n",
      "f1_score - 0.9973986984963624\n",
      "\n",
      "matrix1 - Test Data -\n",
      "Accuracy - 0.9224806201550387\n",
      "Precision - 0.9300067735380447\n",
      "Recall - 0.9224806201550387\n",
      "f1_score - 0.9182065924644426\n",
      "\n",
      "matrix2 - Train Data -\n",
      "Accuracy - 1.0\n",
      "Precision - 1.0\n",
      "Recall - 1.0\n",
      "f1_score - 1.0\n",
      "\n",
      "matrix2 - Test Data -\n",
      "Accuracy - 0.7984496124031008\n",
      "Precision - 0.793035560477421\n",
      "Recall - 0.7984496124031008\n",
      "f1_score - 0.7787115744453355\n"
     ]
    }
   ],
   "source": [
    "logreg= LogisticRegression(solver='lbfgs')\n",
    "\n",
    "fit = logreg.fit(X_train1,y_train1)\n",
    "preds = fit.predict(X_train1)\n",
    "print(\"\\nmatrix1 - Train Data -\")\n",
    "errors_metrics(y_train1,preds)\n",
    "\n",
    "preds = fit.predict(X_test1)\n",
    "print(\"\\nmatrix1 - Test Data -\")\n",
    "errors_metrics(y_test1,preds)\n",
    "\n",
    "logreg= LogisticRegression()\n",
    "fit = logreg.fit(X_train2,y_train2)\n",
    "preds = fit.predict(X_train2)\n",
    "print(\"\\nmatrix2 - Train Data -\")\n",
    "errors_metrics(y_train2,preds)\n",
    "\n",
    "preds = fit.predict(X_test2)\n",
    "print(\"\\nmatrix2 - Test Data -\")\n",
    "errors_metrics(y_test2,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for Logistic Regression:\n",
    "\n",
    "Unigram model got an test accuracy of 92.2%;\n",
    "unigram-bigram model got an test accuracy of 79.8%. \n",
    "\n",
    "Unigram model(matrix1) is performing better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's try using another machine learning technique to classify these reviews as positive or negative. Go through the exact same exercise in the previous step, except this time, use Naive Bayes instead of Logistic Regression.\n",
    "\n",
    "For count data, use [Multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). For binary data, use [Bernoulli Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB).\n",
    "\n",
    "Compare the results of both the Logistic Regression and Naive Bayes models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "matrix1 Multinomial Naive Bayes- Train Data:\n",
      "Accuracy - 0.9662337662337662\n",
      "Precision - 0.9666365209185279\n",
      "Recall - 0.9662337662337662\n",
      "f1_score - 0.9657448498043414\n",
      "\n",
      "matrix1 Multinomial Naive Bayes - Test Data:\n",
      "Accuracy - 0.9224806201550387\n",
      "Precision - 0.9257919147396467\n",
      "Recall - 0.9224806201550387\n",
      "f1_score - 0.9192339966434909\n",
      "\n",
      "matrix2 Bernoulli Naive Bayes - Train Data:\n",
      "Accuracy - 0.8181818181818182\n",
      "Precision - 0.8481954212613237\n",
      "Recall - 0.8181818181818182\n",
      "f1_score - 0.7838383838383837\n",
      "\n",
      "matrix2 Bernoulli Naive Bayes - Test Data:\n",
      "Accuracy - 0.7286821705426356\n",
      "Precision - 0.7038327247101032\n",
      "Recall - 0.7286821705426356\n",
      "f1_score - 0.6597275296914996\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "fit = mnb.fit(X_train1,y_train1)\n",
    "preds = fit.predict(X_train1)\n",
    "print(\"\\nmatrix1 Multinomial Naive Bayes- Train Data:\")\n",
    "errors_metrics(y_train1,preds)\n",
    "\n",
    "preds = fit.predict(X_test1)\n",
    "print(\"\\nmatrix1 Multinomial Naive Bayes - Test Data:\")\n",
    "errors_metrics(y_test1,preds)\n",
    "\n",
    "bnb= BernoulliNB()\n",
    "fit = bnb.fit(X_train2,y_train2)\n",
    "preds = fit.predict(X_train2)\n",
    "print(\"\\nmatrix2 Bernoulli Naive Bayes - Train Data:\")\n",
    "errors_metrics(y_train2,preds)\n",
    "\n",
    "preds = fit.predict(X_test2)\n",
    "print(\"\\nmatrix2 Bernoulli Naive Bayes - Test Data:\")\n",
    "errors_metrics(y_test2,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Logistic Regression Accuracy-\n",
    "    Unigram Test: 92.2%;\n",
    "    Unigram-bigram Test:79.8%\n",
    "\n",
    " Naive Bayes Accuracy-\n",
    "    Multinomial matrix1 Test: 92.2%;\n",
    "    Bernoulli matrix2 Test: 72.8%\n",
    "\n",
    "Logistic regression with unigram words and multinomial naive bayes with unigram words are performing equally well both with accuracy of 92.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, we've been using Count Vectorizer to create document-term matrices to input into the models. For at least one of the four models you've created so far, use TF-IDF Vectorizer instead of Count Vectorizer, and see if it improves the results.\n",
    "\n",
    "Out of all of the models you've created, which model do you think best classifies positive and negative cappuccino cup reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(stop_words='english')\n",
    "# tokenize and build vocab\n",
    "tfv.fit(dataset.reviews)\n",
    "dtm = tfv.transform(dataset.reviews)\n",
    "matrix3 = pd.DataFrame(dtm.toarray(), columns=tfv.get_feature_names())\n",
    "matrix3[\"sentiment\"] = dataset.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(matrix3.drop(\"sentiment\",axis=1),matrix3[[\"sentiment\"]],test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "matrix3 TFIDF Multinomial Naive Bayes- Train Data -\n",
      "Accuracy - 0.787012987012987\n",
      "Precision - 0.8351257557869128\n",
      "Recall - 0.787012987012987\n",
      "f1_score - 0.731267421329533\n",
      "\n",
      "matrix3 TFIDF Multinomial Naive Bayes- Test Data -\n",
      "Accuracy - 0.7209302325581395\n",
      "Precision - 0.7994186046511628\n",
      "Recall - 0.7209302325581395\n",
      "f1_score - 0.6115722710581951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "fit = mnb.fit(X_train3,y_train3)\n",
    "preds = fit.predict(X_train3)\n",
    "print(\"\\nmatrix3 TFIDF Multinomial Naive Bayes- Train Data -\")\n",
    "errors_metrics(y_train3,preds)\n",
    "\n",
    "preds = fit.predict(X_test3)\n",
    "print(\"\\nmatrix3 TFIDF Multinomial Naive Bayes- Test Data -\")\n",
    "errors_metrics(y_test3,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "matrix3 TFIDF - Train Data -\n",
      "Accuracy - 0.8545454545454545\n",
      "Precision - 0.8787159428108984\n",
      "Recall - 0.8545454545454545\n",
      "f1_score - 0.8343413697527137\n",
      "\n",
      "matrix3 TFIDF - Test Data -\n",
      "Accuracy - 0.7441860465116279\n",
      "Precision - 0.8117209302325582\n",
      "Recall - 0.7441860465116279\n",
      "f1_score - 0.6606878200386334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\meena\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "fit = logreg.fit(X_train3,y_train3)\n",
    "preds = fit.predict(X_train3)\n",
    "print(\"\\nmatrix3 TFIDF - Train Data -\")\n",
    "errors_metrics(y_train3,preds)\n",
    "\n",
    "preds = fit.predict(X_test3)\n",
    "print(\"\\nmatrix3 TFIDF - Test Data -\")\n",
    "errors_metrics(y_test3,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Accuracy-\n",
    "    Unigram matrix1 Test: 92.2%;\n",
    "    Unigram-bigram matrix2 Test:79.8%;\n",
    "    TFIDF matrix3 Test: 74.4%\n",
    "\n",
    "Naive Bayes Accuracy-\n",
    "    Multinomial matrix1 Test: 92.2%;\n",
    "    Bernoulli matrix2 Test: 72.8%;\n",
    "    Multinomial TFIDF matrix3 Test:72.1%\n",
    "\n",
    "Logistic regression with unigram words and multinomial naive bayes with unigram words and count vectorizer are performing equally well both with accuracy of 92.2%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
